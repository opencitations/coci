{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import ReadTimeout, ConnectTimeout\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import csv\n",
    "from time import sleep\n",
    "from duration import (\n",
    "    to_iso8601,\n",
    "    to_seconds,\n",
    "    to_timedelta,\n",
    "    to_tuple,\n",
    ")\n",
    "\n",
    "conf = {\n",
    "    \"email\": \"ivan.heibi2@unibo.it\",\n",
    "    \"key\": None,\n",
    "    \"useragent\": \"opencitations\",\n",
    "    \"postfix\": \"00000\"\n",
    "}\n",
    "\n",
    "\n",
    "CROSSREF_CODE = '020'\n",
    "LOOKUP_CSVPATH = 'lookup.csv'\n",
    "DATA_CSVPATH = \"data/d-%s.csv\"\n",
    "PROV_CSVPATH = 'prov/p-%s.csv'\n",
    "INDEX_CI_CSVPATH = 'index/ci.csv'\n",
    "INDEX_DATE_CSVPATH = 'index/date.csv'\n",
    "INDEX_NODOI_CSVPATH = 'index/nodoi.csv'\n",
    "\n",
    "MAX_DATA_ENTRIES = 1000000\n",
    "datacsv_counter = 0\n",
    "file_id = 0\n",
    "\n",
    "MIN_SCORE = 75\n",
    "crossref_api = {\n",
    "    'free_text' : 'https://api.crossref.org/works?rows=1&query=%s&mailto='+conf[\"email\"],\n",
    "    'doi' : 'https://api.crossref.org/works/&mailto='+conf[\"email\"]+'&query=%s'\n",
    "}\n",
    "\n",
    "lookup_code = 0\n",
    "lookup_dic = {}\n",
    "ci_index_dic = {}\n",
    "date_index_dic = {}\n",
    "nodoi_index_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### Methods to write on CSV files\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "#def write_row_on_csv(csv_path, new_row, csvid = None, quoting_val = csv.QUOTE_NONE):\n",
    "#    if csvid != None: \n",
    "#        csv_path = csv_path%(csvid)\n",
    "#    with open(csv_path, 'a', newline='') as csvfile:\n",
    "#        csvwriter = csv.writer(csvfile, quoting= quoting_val)\n",
    "#        csvwriter.writerow(new_row)\n",
    "\n",
    "#write on a csv_path file a given block_txt \n",
    "def write_txtblock_on_csv(csv_path, block_txt, csvid = None):\n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt)\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "def write_rows_on_csv(csv_path, row_lis, csvid = None, quoting_flag= True):\n",
    "    block_txt = \"\"\n",
    "    for row in row_lis:\n",
    "        row_txt = \"\"\n",
    "        separator = \",\"\n",
    "        for field_i in range(0,len(row)):\n",
    "            if (field_i == len(row) - 1):\n",
    "                separator = \"\"\n",
    "            field = row[field_i]\n",
    "            if quoting_flag:\n",
    "                field = '\"'+field+'\"'\n",
    "            row_txt = row_txt + field + separator\n",
    "        block_txt = block_txt + row_txt + \"\\n\"\n",
    "    \n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############  Convert CrossRef DOI and update the lookup csv\n",
    "\n",
    "#init the lookup_dic by the contents of its corresponding csv\n",
    "def init_lookup_dic():\n",
    "    with open(LOOKUP_CSVPATH,'r') as lookupcsv:\n",
    "        lookupcsv_reader = csv.DictReader(lookupcsv)\n",
    "        for row in lookupcsv_reader:\n",
    "            lookup_dic[row['c']] = row['code']\n",
    "        #last code used\n",
    "        global lookup_code\n",
    "        lookup_code = len(lookup_dic) - 1\n",
    "    #the original csv file didn't end with a \\n therefore appending new lines\n",
    "    #will put write the first line next to the last one\n",
    "    write_txtblock_on_csv(LOOKUP_CSVPATH, \"\\n\")\n",
    "\n",
    "#update lookup dictionary and update its corresponding csv\n",
    "def update_lookup(c):\n",
    "    #define the code following the 9 rule ... \n",
    "    calc_next_lookup_code()\n",
    "    code = lookup_code  \n",
    "    global lookup_dic\n",
    "    lookup_dic[c] = code\n",
    "    #add it on the csv\n",
    "    write_txtblock_on_csv(LOOKUP_CSVPATH, '\"%s\",\"%s\"\\n'%(c,code))\n",
    "\n",
    "def calc_next_lookup_code():  \n",
    "    global lookup_code\n",
    "    rem = lookup_code % 100\n",
    "    newcode = lookup_code + 1\n",
    "    if (rem==89):\n",
    "        newcode = newcode * 10\n",
    "    lookup_code = newcode\n",
    "    \n",
    "#convert a crossref doi into a citation identifier     \n",
    "def convert_doi_to_ci(doi_str):\n",
    "    return CROSSREF_CODE + match_str_to_lookup(doi_str)\n",
    "   \n",
    "#convert a giving string in its corresponding ci format\n",
    "#using the lookup file\n",
    "def match_str_to_lookup(str_val):\n",
    "    ci_str = \"\"\n",
    "    for c in str_val:\n",
    "        if c not in lookup_dic:\n",
    "            update_lookup(c)\n",
    "        ci_str = ci_str + str(lookup_dic[c])\n",
    "    return ci_str    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a bib citation with all the available info inside the reference object \n",
    "def build_bibc(obj):\n",
    "    \n",
    "    if 'unstructured' in obj:\n",
    "        return obj['unstructured']\n",
    "    else:\n",
    "        #all att values are already in string format\n",
    "        bibc = \"\"\n",
    "        strspan= \" \"\n",
    "        if 'author' in obj:\n",
    "            bibc = bibc + obj['author'] + strspan          \n",
    "        if 'year' in obj:\n",
    "            bibc = bibc + obj['year'] + strspan\n",
    "        if 'article-title' in obj:\n",
    "            bibc = bibc + obj['article-title'] + strspan\n",
    "        if 'volume-title' in obj:\n",
    "            bibc = bibc + obj['volume-title'] + strspan\n",
    "        if 'journal-title' in obj:\n",
    "            bibc = bibc + obj['journal-title'] + strspan\n",
    "        if 'volume' in obj:\n",
    "            bibc = bibc + obj['volume'] + strspan\n",
    "        if 'first-page' in obj:\n",
    "            bibc = bibc + obj['first-page'] + strspan\n",
    "        if 'last-page' in obj:\n",
    "            bibc = bibc + obj['last-page'] + strspan\n",
    "        return bibc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call crossref with the corresponding crossref_api[query_type] and the query_text \n",
    "def get_data(query_text, is_json = True, query_type = \"free_text\", num_iterations= 1, sleep_time= 60,req_timeout= None):\n",
    "    api_url = crossref_api[query_type]\n",
    "    errors = \"\"\n",
    "    for i in range(0,num_iterations):\n",
    "        api_call = api_url % (urllib.parse.quote_plus(query_text))\n",
    "        print(api_call)\n",
    "        try:\n",
    "            response = requests.get(api_call, headers={\"User-Agent\": conf[\"useragent\"]}, timeout= req_timeout)\n",
    "            if (response.status_code == 200):\n",
    "                if is_json:\n",
    "                    return json.loads(response.text)\n",
    "                else:\n",
    "                    return response.text\n",
    "            else:\n",
    "                errors = errors + \"HTTP error on data retrieving (HTTP status code: %s). \" % str(response.status_code)\n",
    "        except Exception as e:\n",
    "            errors = errors + \"Exception: %s \" % e\n",
    "        \n",
    "        #try again after a sleep_time period\n",
    "        sleep(sleep_time)\n",
    "    \n",
    "    #if the method arrives here, we got some errors\n",
    "    return {\"errors\": errors} \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the publication-date of a given crossref work object\n",
    "def build_pubdate(obj):\n",
    "    if 'issued' in obj:\n",
    "        if 'date-parts' in obj['issued']:\n",
    "            #is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj['issued']['date-parts'][0]\n",
    "                \n",
    "                #lisdate[year,month,day]\n",
    "                listdate = [1,1,1]\n",
    "                for i in range(0,len(obj_date)):\n",
    "                    listdate[i] = obj_date[i]\n",
    "                    \n",
    "                #I have a date , so generate it\n",
    "                if (listdate[0] != 1):\n",
    "                    date_val = datetime.date(listdate[0], listdate[1], listdate[2])\n",
    "                    if ((listdate[1] == 1) and (listdate[2] == 1)):\n",
    "                        #e.g: 2016/1/1\n",
    "                        date_in_str = date_val.strftime('%Y')\n",
    "                    else:\n",
    "                        #e.g: 2016/3/1\n",
    "                        date_in_str = date_val.strftime('%Y-%m-%d')\n",
    "                    return date_in_str\n",
    "                \n",
    "            except IndexError:\n",
    "                pass\n",
    "    return -1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a textual input (query_txt), call crossref and retrieves the work object of \n",
    "# the best scoring result in case the score is higher than MIN_SCORE\n",
    "def find_work(query_txt):\n",
    "    #call cross ref \n",
    "    res = get_data(query_txt, num_iterations=3, req_timeout= 60)\n",
    "    \n",
    "    if \"errors\" not in res:\n",
    "        #crossref first and only result with higher score\n",
    "        work_item = res['message']['items'][0]\n",
    "\n",
    "        if \"score\" in work_item:\n",
    "            if work_item[\"score\"] > MIN_SCORE:\n",
    "                #check if the work got a DOI\n",
    "                if \"DOI\" in work_item:\n",
    "                    return work_item\n",
    "                else:\n",
    "                    return -1\n",
    "            return \"low score\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_list_items(obj):\n",
    "    list_of_items = obj['message']['items']\n",
    "    for item in list_of_items:\n",
    "        csvdata = process_item(item)\n",
    "        if \"errors\" in csvdata:\n",
    "            #write the errors\n",
    "            write_txtblock_on_csv(INDEX_CI_CSVPATH, csvdata[\"citing_ci\"]+\",\"+csvdata['errors'])\n",
    "        else:\n",
    "            write_txtblock_on_csv(DATA_CSVPATH, csvdata[\"data\"], csvid = str(file_id))\n",
    "            write_txtblock_on_csv(PROV_CSVPATH, csvdata[\"prov\"], csvid = str(file_id))\n",
    "            write_txtblock_on_csv(INDEX_CI_CSVPATH, csvdata[\"citing_ci\"]+\",\"+\"ok\")\n",
    "        \n",
    "#given a crossref object get all the COCI data needed, returns an object with errors in case something wrong happend \n",
    "def process_item(obj):\n",
    "    data_lis = []\n",
    "    prov_lis = []\n",
    "    if \"DOI\" in obj:\n",
    "        citing_doi = obj[\"DOI\"].lower()\n",
    "        citing_ci = convert_doi_to_ci(citing_doi)\n",
    "        citing_date = build_pubdate(obj)\n",
    "        \n",
    "        #in case this is the first time i am elaborating this item\n",
    "        if citing_ci not in ci_index_dic:\n",
    "            ci_index_dic[citing_ci] = 1\n",
    "            \n",
    "            #check if obj has a date\n",
    "            if citing_date != -1 :\n",
    "                #iterate through all references\n",
    "                references = obj['reference']\n",
    "                for ref_item in references:\n",
    "                    ref_entry_attr = process_ref_entry(ref_item)\n",
    "                    if(\"errors\" not in ref_entry_attr): \n",
    "                        #create all other data needed\n",
    "                        oci = citing_ci+\"-\"+ref_entry_attr['cited_ci']\n",
    "                        timespan = to_iso8601(citing_date - ref_entry_attr['cited_date'])\n",
    "                        \n",
    "                        data_txtblock = oci+\",\"+citing_doi+\",\"+ref_entry_attr['cited_doi']+\",\"+citing_date+\",\"+timespan+\"\\n\"\n",
    "                        prov_txtblock = oci+\",\"+\"crossref\"+\",\"+crossref_api['doi']+str(citing_doi)+\",\"+citing_date+\"\\n\"\n",
    "\n",
    "                    #we have errors\n",
    "                    else:\n",
    "                        #break all and return the errors\n",
    "                        return {\"errors\": ref_entry_attr[\"errors\"], \"citing_ci\": citing_ci}\n",
    "                        break;\n",
    "                    \n",
    "                #once i am done with all the references, write all to csv  \n",
    "                #update files identifiers\n",
    "                global datacsv_counter\n",
    "                global file_id\n",
    "                datacsv_counter += 1\n",
    "                if (datacsv_counter // MAX_DATA_ENTRIES == 1):\n",
    "                    datacsv_counter = 0\n",
    "                    file_id += 1 \n",
    "                    \n",
    "                return {\n",
    "                    \"oci\": oci,\n",
    "                    \"citing_ci\": citing_ci,\n",
    "                    \"data\": data_txtblock,\n",
    "                    \"prov\": prov_txtblock\n",
    "                }\n",
    "            \n",
    "#given a reference entry returns it's DOI, CI, and Publication-Date    \n",
    "#in case one of these attributes is not present: the object will contain the errors string\n",
    "def process_ref_entry(obj):\n",
    "    \n",
    "    #check if obj have a DOI if not call crossref\n",
    "    if \"DOI\" not in obj :\n",
    "        query_text = build_bibc(obj)\n",
    "        obj = find_work(query_text)\n",
    "    \n",
    "    #if my new object have a doi now\n",
    "    if \"DOI\" in obj:\n",
    "        cited_doi = obj[\"DOI\"]\n",
    "        cited_ci = convert_doi_to_ci(cited_doi)\n",
    "        \n",
    "        #check if obj have a publcation date, \n",
    "        #first case is true only if find_work has been called before\n",
    "        creation_date = build_pubdate(obj)\n",
    "        if creation_date == -1 :\n",
    "            obj = get_data(cited_doi, query_type = \"doi\", num_iterations=3, req_timeout=60)\n",
    "            if \"errors\" not in obj:\n",
    "                creation_date = build_pubdate(obj['message'])\n",
    "                return {'cited_doi': cited_doi, 'cited_ci': cited_ci, 'cited_date':creation_date }\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lookup.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-da40cdbee830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##test doi converter and and lookup update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minit_lookup_dic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#write_txtblock_on_csv(LOOKUP_CSVPATH, '\"ò#\",\"68\"\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmatch_str_to_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"10.11/ç§1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d6d1d19bee16>\u001b[0m in \u001b[0;36minit_lookup_dic\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#init the lookup_dic by the contents of its corresponding csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_lookup_dic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOOKUP_CSVPATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlookupcsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlookupcsv_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookupcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookupcsv_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lookup.csv'"
     ]
    }
   ],
   "source": [
    "##################SOME TESTS\n",
    "\n",
    "##test doi converter and and lookup update\n",
    "init_lookup_dic()\n",
    "#write_txtblock_on_csv(LOOKUP_CSVPATH, '\"ò#\",\"68\"\\n')\n",
    "match_str_to_lookup(\"10.11/ç§1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.crossref.org/works?rows=1&query=Constantin%2C+A.%2C+Peroni%2C+S.%2C+Pettifer%2C+S.%2C+Shotton%2C+D.%2C+Vitali%2C+F.+%28in+press%29.+The+Document+Components+Ontology+%28DoCO%29.+To+appear+in+Semantic+Web+%E2%80%93+Interoperability%2C+Usability%2C+Applicability.+Amsterdam%2C+The+Netherlands%3A+IOS+Press.&mailto=ivan.heibi2@unibo.it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10.3233/sw-150177'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make general textual query and retrieve the DOI\n",
    "query_txt = \"Constantin, A., Peroni, S., Pettifer, S., Shotton, D., Vitali, F. (in press). The Document Components Ontology (DoCO). To appear in Semantic Web – Interoperability, Usability, Applicability. Amsterdam, The Netherlands: IOS Press.\"\n",
    "#The DOI is: 10.3233/SW-150177\n",
    "find_work(query_txt)['DOI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.crossref.org/works/10.1093%2Fbioinformatics%2Fbtq383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cited_ci': '0200100370100090336111824182315242722102918122836112926030803',\n",
       " 'cited_date': '2010-09-07',\n",
       " 'cited_doi': '10.1093/bioinformatics/btq383'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A sample of work references\n",
    "reference = {\"reference\": [\n",
    "          {\n",
    "            \"issue\": \"18\",\n",
    "            \"key\": \"10.3233/SW-150177_ref1\",\n",
    "            \"doi-asserted-by\": \"crossref\",\n",
    "            \"first-page\": \"i568\",\n",
    "            \"DOI\": \"10.1093/bioinformatics/btq383\",\n",
    "            \"article-title\": \"Utopia documents: linking scholarly literature with research data\",\n",
    "            \"volume\": \"26\",\n",
    "            \"author\": \"Attwood\",\n",
    "            \"year\": \"2010\",\n",
    "            \"journal-title\": \"Bioinformatics\"\n",
    "          },\n",
    "          {\n",
    "            \"issue\": \"6\",\n",
    "            \"key\": \"10.3233/SW-150177_ref5\",\n",
    "            \"first-page\": \"515\",\n",
    "            \"article-title\": \"The collections ontology: creating and handling collections in OWL 2 DL frameworks\",\n",
    "            \"volume\": \"5\",\n",
    "            \"author\": \"Ciccarese\",\n",
    "            \"year\": \"2014\",\n",
    "            \"journal-title\": \"Semantic Web – Interoperability, Usability, Applicability\"\n",
    "          },\n",
    "        ]\n",
    "}\n",
    "first_ref = reference['reference'][0];\n",
    "process_ref_entry(first_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test the date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_lookup_dic()\n",
    "convert_doi_to_ci('10.3233/sw-150177') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = date_val = datetime.date(2012, 3, 1)\n",
    "t2 = date_val = datetime.date(2013, 3, 1)\n",
    "time = t2 - t1\n",
    "to_iso8601(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROV_CSVPATH = 'prov/p-%s.csv'\n",
    "print(PROV_CSVPATH%(1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
