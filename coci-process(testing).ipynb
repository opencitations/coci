{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import ReadTimeout, ConnectTimeout\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import csv\n",
    "from time import sleep\n",
    "from duration import (\n",
    "    to_iso8601,\n",
    "    to_seconds,\n",
    "    to_timedelta,\n",
    "    to_tuple,\n",
    ")\n",
    "\n",
    "conf = {\n",
    "    \"email\": \"ivan.heibi2@unibo.it\",\n",
    "    \"key\": None,\n",
    "    \"useragent\": \"coci-process\",\n",
    "    \"postfix\": \"00000\"\n",
    "}\n",
    "\n",
    "\n",
    "CROSSREF_CODE = '020'\n",
    "LOOKUP_CSVPATH = 'lookup.csv'\n",
    "DATA_CSVPATH = \"data/d-%s.csv\"\n",
    "PROV_CSVPATH = 'prov/p-%s.csv'\n",
    "INDEX_PROCESSED_CSVPATH = 'index/processed.csv'\n",
    "INDEX_ERRORS_CSVPATH = 'index/error.csv'\n",
    "INDEX_DATE_CSVPATH = 'index/date.csv'\n",
    "INDEX_NODOI_CSVPATH = 'index/nodoi.csv'\n",
    "INDEX_FILE_CSVPATH = 'index/file.csv'\n",
    "\n",
    "INPUT_DATA_PATH = '.'\n",
    "\n",
    "MAX_DATA_ENTRIES = 5\n",
    "datacsv_counter = 0\n",
    "file_id = 0\n",
    "\n",
    "MIN_SCORE = 75\n",
    "crossref_api = {\n",
    "    'free_text' : 'https://api.crossref.org/works?rows=1&query=%s&mailto='+conf[\"email\"],\n",
    "    'doi' : 'https://api.crossref.org/works/&mailto='+conf[\"email\"]+'&query=%s'\n",
    "}\n",
    "\n",
    "lookup_code = 0\n",
    "\n",
    "#dictionaries \n",
    "lookup_dic = {}\n",
    "processed_dic = {}\n",
    "date_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### Methods to write on CSV files\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "#def write_row_on_csv(csv_path, new_row, csvid = None, quoting_val = csv.QUOTE_NONE):\n",
    "#    if csvid != None: \n",
    "#        csv_path = csv_path%(csvid)\n",
    "#    with open(csv_path, 'a', newline='') as csvfile:\n",
    "#        csvwriter = csv.writer(csvfile, quoting= quoting_val)\n",
    "#        csvwriter.writerow(new_row)\n",
    "\n",
    "#create new file with header\n",
    "def init_csv(csv_path,header):\n",
    "    with open(csv_path, 'w') as csvfile:\n",
    "        csvfile.write(header)\n",
    "\n",
    "#write on a csv_path file a given block_txt \n",
    "def write_txtblock_on_csv(csv_path, block_txt, csvid = None):\n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt)\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "def write_rows_on_csv(csv_path, row_lis, csvid = None, quoting_flag= True):\n",
    "    block_txt = \"\"\n",
    "    for row in row_lis:\n",
    "        row_txt = \"\"\n",
    "        separator = \",\"\n",
    "        for field_i in range(0,len(row)):\n",
    "            if (field_i == len(row) - 1):\n",
    "                separator = \"\"\n",
    "            field = row[field_i]\n",
    "            if quoting_flag:\n",
    "                field = '\"'+field+'\"'\n",
    "            row_txt = row_txt + field + separator\n",
    "        block_txt = block_txt + row_txt + \"\\n\"\n",
    "    \n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#init the lookup_dic by the contents of its corresponding csv\n",
    "def init_lookup_dic():\n",
    "    with open(LOOKUP_CSVPATH,'r') as lookupcsv:\n",
    "        lookupcsv_reader = csv.DictReader(lookupcsv)\n",
    "        for row in lookupcsv_reader:\n",
    "            lookup_dic[row['c']] = row['code']\n",
    "        #last code used\n",
    "        global lookup_code\n",
    "        lookup_code = len(lookup_dic) - 1\n",
    "\n",
    "#update lookup dictionary and update its corresponding csv\n",
    "def update_lookup(c):\n",
    "    #define the code following the 9 rule ... \n",
    "    calc_next_lookup_code()\n",
    "    code = lookup_code  \n",
    "    global lookup_dic\n",
    "    lookup_dic[c] = code\n",
    "    #add it on the csv\n",
    "    write_txtblock_on_csv(LOOKUP_CSVPATH, '\\n\"%s\",\"%s\"'%(c,code))\n",
    "\n",
    "def update_date(dateObj, ci_key):\n",
    "    global date_dic\n",
    "    date_dic[ci_key] = dateObj\n",
    "    write_txtblock_on_csv(INDEX_DATE_CSVPATH, \"\\n\"+ci_key+\",\"+dateObj[\"str_val\"]+\",\"+str(dateObj[\"format\"]))\n",
    "    \n",
    "def init_date_dic():\n",
    "    with open(INDEX_DATE_CSVPATH,'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        global date_dic\n",
    "        for row in csv_reader:\n",
    "            date_dic[row['id']] = {\"str_val\": row['value'],\"format\": row['format']}\n",
    "            \n",
    "def update_processed(ci_key):\n",
    "    global processed_dic\n",
    "    processed_dic[ci_key] = 1\n",
    "    write_txtblock_on_csv(INDEX_PROCESSED_CSVPATH, \"\\n\"+ci_key)\n",
    "    \n",
    "def init_processed_dic():\n",
    "    with open(INDEX_PROCESSED_CSVPATH,'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        global processed_dic\n",
    "        for row in csv_reader:\n",
    "            processed_dic[row['id']] = 1\n",
    "            \n",
    "def update_nodoi(citing, cited, text):\n",
    "    write_txtblock_on_csv(INDEX_NODOI_CSVPATH, '\\n%s,%s,\"%s\"'%(citing,cited,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############  Convert CrossRef DOI to CI\n",
    "def calc_next_lookup_code():  \n",
    "    global lookup_code\n",
    "    rem = lookup_code % 100\n",
    "    newcode = lookup_code + 1\n",
    "    if (rem==89):\n",
    "        newcode = newcode * 10\n",
    "    lookup_code = newcode\n",
    "    \n",
    "#convert a crossref doi into a citation identifier     \n",
    "def convert_doi_to_ci(doi_str):\n",
    "    return CROSSREF_CODE + match_str_to_lookup(doi_str)\n",
    "   \n",
    "#convert a giving string in its corresponding ci format\n",
    "#using the lookup file\n",
    "def match_str_to_lookup(str_val):\n",
    "    ci_str = \"\"\n",
    "    str_noprefix = str_val[3:]\n",
    "    for c in str_noprefix:\n",
    "        if c not in lookup_dic:\n",
    "            update_lookup(c)\n",
    "        ci_str = ci_str + str(lookup_dic[c])\n",
    "    return ci_str    \n",
    "\n",
    "def reverse_ci_to_doi(str_val):\n",
    "    str_val = str_val[3:]\n",
    "    str_doi=\"\"\n",
    "    i=0\n",
    "    while i < len(str_val):\n",
    "        code = str_val[i:i+2]\n",
    "        \n",
    "        for key in lookup_dic:\n",
    "            if lookup_dic[key] == code:\n",
    "                    str_doi = str_doi + key\n",
    "        i += 2\n",
    "    return \"10.\"+str_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a bib citation with all the available info inside the reference object \n",
    "def build_bibc(obj):\n",
    "    \n",
    "    if 'unstructured' in obj:\n",
    "        return obj['unstructured']\n",
    "    else:\n",
    "        #all att values are already in string format\n",
    "        bibc = \"\"\n",
    "        strspan= \" \"\n",
    "        if 'author' in obj:\n",
    "            bibc = bibc + obj['author'] + strspan          \n",
    "        if 'year' in obj:\n",
    "            bibc = bibc + obj['year'] + strspan\n",
    "        if 'article-title' in obj:\n",
    "            bibc = bibc + obj['article-title'] + strspan\n",
    "        if 'volume-title' in obj:\n",
    "            bibc = bibc + obj['volume-title'] + strspan\n",
    "        if 'journal-title' in obj:\n",
    "            bibc = bibc + obj['journal-title'] + strspan\n",
    "        if 'volume' in obj:\n",
    "            bibc = bibc + obj['volume'] + strspan\n",
    "        if 'first-page' in obj:\n",
    "            bibc = bibc + obj['first-page'] + strspan\n",
    "        if 'last-page' in obj:\n",
    "            bibc = bibc + obj['last-page'] + strspan\n",
    "        return bibc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call crossref with the corresponding crossref_api[query_type] and the query_text \n",
    "def get_data(query_text, is_json = True, query_type = \"free_text\", num_iterations= 1, sleep_time= 60,req_timeout= None):\n",
    "    api_url = crossref_api[query_type]\n",
    "    errors = \"\"\n",
    "    for i in range(0,num_iterations):\n",
    "        api_call = api_url % (urllib.parse.quote_plus(query_text))\n",
    "        #print(api_call)\n",
    "        try:\n",
    "            response = requests.get(api_call, headers={\"User-Agent\": conf[\"useragent\"]}, timeout= req_timeout)\n",
    "            if (response.status_code == 200):\n",
    "                if is_json:\n",
    "                    return json.loads(response.text)\n",
    "                else:\n",
    "                    return response.text\n",
    "            else:\n",
    "                errors = errors + \"HTTP error on data retrieving (HTTP status code: %s). \" % str(response.status_code)\n",
    "        except Exception as e:\n",
    "            errors = errors + \"Exception: %s \" % e\n",
    "        \n",
    "        #try again after a sleep_time period\n",
    "        sleep(sleep_time)\n",
    "    \n",
    "    #if the method arrives here, we got some errors\n",
    "    return {\"errors\": errors} \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the publication-date of a given crossref work object\n",
    "def build_pubdate(obj, ci):\n",
    "    \n",
    "    if ci in date_dic:\n",
    "        return date_dic[ci]\n",
    "    \n",
    "    if 'issued' in obj:\n",
    "        if 'date-parts' in obj['issued']:\n",
    "            #is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj['issued']['date-parts'][0]\n",
    "                \n",
    "                #lisdate[year,month,day]\n",
    "                listdate = [1,1,1]\n",
    "                for i in range(0,len(obj_date)):\n",
    "                    try:\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                #I have a date , so generate it\n",
    "                if (listdate[0] != 1):\n",
    "                    date_val = datetime.date(listdate[0], listdate[1], listdate[2])\n",
    "                    \n",
    "                    dformat = '%Y-%m-%d'\n",
    "                    #e.g: 2016/1/1\n",
    "                    if ((listdate[1] == 1) and (listdate[2] == 1)):\n",
    "                        dformat = '%Y'\n",
    "\n",
    "                    #e.g: 2016/3/1\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    \n",
    "                    dateobj = {\"str_val\": date_in_str, \"format\":  dformat}\n",
    "                    #date_dic[ci] = dateobj\n",
    "                    return dateobj\n",
    "                \n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    #date_dic[ci] = {\"str_val\":\"\",\"format\":-1}\n",
    "    return {\"str_val\":\"\",\"format\":-1}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a textual input (query_txt), call crossref and retrieves the work object of \n",
    "# the best scoring result in case the score is higher than MIN_SCORE\n",
    "def find_work(query_txt):\n",
    "    #call cross ref \n",
    "    res = get_data(query_txt, num_iterations=2, req_timeout= 60)\n",
    "    \n",
    "    if \"errors\" not in res:\n",
    "        try:\n",
    "            #crossref first and only result with higher score\n",
    "            work_item = res['message']['items'][0]\n",
    "\n",
    "            if \"score\" in work_item:\n",
    "                if work_item[\"score\"] > MIN_SCORE:\n",
    "                    #check if the work has a DOI\n",
    "                    if \"DOI\" in work_item:\n",
    "                        return work_item\n",
    "                    else:\n",
    "                        return -1\n",
    "                #low score\n",
    "                return -1\n",
    "        except IndexError:\n",
    "                return -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_list_items(obj, obj_file_id):\n",
    "    list_of_items = obj['message']['items']\n",
    "    for item in list_of_items:\n",
    "        ##process the item \n",
    "        csvdata = process_item(item)\n",
    "        \n",
    "        #if this is the first time i am processing this element\n",
    "        if csvdata != -1:\n",
    "            if \"errors\" in csvdata:\n",
    "                #write the errors\n",
    "                write_txtblock_on_csv(INDEX_ERRORS_CSVPATH, '\\n%s,\"%s\"'%(csvdata[\"citing_ci\"],csvdata['errors']))\n",
    "\n",
    "            else:    \n",
    "                global datacsv_counter\n",
    "                global file_id\n",
    "                \n",
    "                #update files identifiers\n",
    "                datacsv_counter += 1\n",
    "                if (datacsv_counter // MAX_DATA_ENTRIES == 1):\n",
    "                    datacsv_counter = 0\n",
    "                    file_id += 1 \n",
    "                    init_csv(DATA_CSVPATH%str(file_id),'oci,citing,cited,creation,timestamp')\n",
    "                    init_csv(PROV_CSVPATH%str(file_id),'oci,agent,source,datetime')\n",
    "                \n",
    "                if csvdata[\"data\"] != \"\":\n",
    "                    write_txtblock_on_csv(DATA_CSVPATH, csvdata[\"data\"], csvid = str(file_id))\n",
    "                if csvdata[\"prov\"] != \"\":\n",
    "                    write_txtblock_on_csv(PROV_CSVPATH, csvdata[\"prov\"], csvid = str(file_id))\n",
    "\n",
    "            #add item to processed \n",
    "            write_txtblock_on_csv(INDEX_PROCESSED_CSVPATH, \"\\n%s\"%(csvdata[\"citing_ci\"]))\n",
    "            \n",
    "    write_txtblock_on_csv(INDEX_FILE_CSVPATH, \"\\n%s\"%(str(obj_file_id)))\n",
    "        \n",
    "#given a crossref object get all the COCI data needed, returns an object with errors in case something wrong happend \n",
    "#returns -1 in case the object has already been processed\n",
    "def process_item(obj):\n",
    "    data_lis = []\n",
    "    prov_lis = []\n",
    "    \n",
    "    if ((\"DOI\" in obj) and (\"reference\" in obj)):\n",
    "        print(\"Processing:\"+obj[\"DOI\"])\n",
    "        citing_doi = obj[\"DOI\"].lower()\n",
    "        citing_ci = convert_doi_to_ci(citing_doi)\n",
    "        citing_date = build_pubdate(obj,citing_ci)\n",
    "        \n",
    "        #update dates\n",
    "        update_date(citing_date, citing_ci)\n",
    "        \n",
    "        #in case this is the first time i am elaborating this item\n",
    "        if citing_ci not in processed_dic:\n",
    "            update_processed(citing_ci)\n",
    "                \n",
    "            data_txtblock = \"\"\n",
    "            prov_txtblock = \"\"\n",
    "            \n",
    "            #iterate through all references\n",
    "            for ref_item in obj['reference']:\n",
    "                \n",
    "                ref_entry_attr = process_ref_entry(ref_item)\n",
    "                \n",
    "                if(ref_entry_attr != -1):\n",
    "                    if(\"errors\" not in ref_entry_attr): \n",
    "                        \n",
    "                        #in case It was a No-DOI \n",
    "                        if (ref_entry_attr[\"nodoi_text\"] != -1):\n",
    "                            update_nodoi(citing_ci, ref_entry_attr['cited_ci'], ref_entry_attr[\"nodoi_text\"])\n",
    "                        \n",
    "                        #create all other data needed\n",
    "                        oci = citing_ci+\"-\"+ref_entry_attr['cited_ci']\n",
    "                        \n",
    "                        timestamp = \"\"\n",
    "                        if ((citing_date[\"format\"] != -1) and (ref_entry_attr['cited_date'][\"format\"] != -1)):\n",
    "                            \n",
    "                            citing_dt = datetime.datetime.strptime(citing_date[\"str_val\"], citing_date[\"format\"])\n",
    "                            cited_dt = datetime.datetime.strptime(ref_entry_attr['cited_date'][\"str_val\"], ref_entry_attr['cited_date'][\"format\"])\n",
    "                            timestamp = to_iso8601(citing_dt - cited_dt)\n",
    "                        \n",
    "                        data_txtblock = data_txtblock +\"\\n\"+ oci+\",\"+citing_doi+\",\"+ref_entry_attr['cited_doi']+\",\"+citing_date[\"str_val\"]+\",\"+timestamp\n",
    "                        \n",
    "                        timenow = str(datetime.datetime.now().replace(microsecond=0))\n",
    "                        prov_txtblock = prov_txtblock +\"\\n\"+ oci+\",\"+conf[\"useragent\"]+\",\"+crossref_api['doi']+citing_doi+\",\"+timenow\n",
    "                    #we have errors\n",
    "                    else:\n",
    "                        #break all and return the errors\n",
    "                        return {\"errors\": ref_entry_attr[\"errors\"], \"citing_ci\": citing_ci}\n",
    "                        break;\n",
    "                \n",
    "            return {\n",
    "                \"citing_ci\": citing_ci,\n",
    "                \"data\": data_txtblock,\n",
    "                \"prov\": prov_txtblock\n",
    "            }\n",
    "        return - 1\n",
    "    return {\"errors\": \"entry without a DOI or Ref-List\"}\n",
    "            \n",
    "#given a reference entry returns it's DOI, CI, and Publication-Date    \n",
    "#in case one of these attributes is not present: the methods returns -1\n",
    "def process_ref_entry(obj):\n",
    "    \n",
    "    nodoi_text = -1\n",
    "    \n",
    "    #check if obj have a DOI if not call crossref\n",
    "    if \"DOI\" not in obj :\n",
    "        query_text = build_bibc(obj)\n",
    "        obj = find_work(query_text)\n",
    "        if (obj != -1):\n",
    "            nodoi_text = query_text\n",
    "    \n",
    "    if (obj != -1):\n",
    "        if \"errors\" in obj:\n",
    "            return obj\n",
    "        else:\n",
    "            #if my new object have a doi now\n",
    "            if \"DOI\" in obj:\n",
    "                cited_doi = obj[\"DOI\"]\n",
    "                cited_ci = convert_doi_to_ci(cited_doi)\n",
    "\n",
    "                #check if obj have a publcation date, \n",
    "                #first case is true only if find_work has been called before\n",
    "                cited_date = build_pubdate(obj,cited_ci)\n",
    "                \n",
    "                #in case i don't have a date, try look at it again\n",
    "                if cited_date[\"format\"] == -1 :\n",
    "                    obj = get_data(cited_doi, query_type = \"doi\", num_iterations=3, req_timeout=60)\n",
    "                    if \"errors\" not in obj:\n",
    "                        cited_date = build_pubdate(obj['message'],cited_ci)\n",
    "                \n",
    "                #update dates\n",
    "                update_date(cited_date, cited_ci)\n",
    "                \n",
    "                return {'cited_doi': cited_doi, 'cited_ci': cited_ci, 'cited_date':cited_date, 'nodoi_text':nodoi_text }\n",
    "    else:\n",
    "        return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'010136686901'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################SOME TESTS\n",
    "\n",
    "##test doi converter and and lookup update\n",
    "init_lookup_dic()\n",
    "#write_txtblock_on_csv(LOOKUP_CSVPATH, '\"ò#\",\"68\"\\n')\n",
    "match_str_to_lookup(\"10.11/ç§1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.3233/sw-150177'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make general textual query and retrieve the DOI\n",
    "query_txt = \"Constantin, A., Peroni, S., Pettifer, S., Shotton, D., Vitali, F. (in press). The Document Components Ontology (DoCO). To appear in Semantic Web – Interoperability, Usability, Applicability. Amsterdam, The Netherlands: IOS Press.\"\n",
    "#The DOI is: 10.3233/SW-150177\n",
    "obj_res = find_work(query_txt)\n",
    "obj_res['DOI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A sample of work references\n",
    "reference = {\"reference\": [\n",
    "          {\n",
    "            \"issue\": \"18\",\n",
    "            \"key\": \"10.3233/SW-150177_ref1\",\n",
    "            \"doi-asserted-by\": \"crossref\",\n",
    "            \"first-page\": \"i568\",\n",
    "            \"DOI\": \"10.1093/bioinformatics/btq383\",\n",
    "            \"article-title\": \"Utopia documents: linking scholarly literature with research data\",\n",
    "            \"volume\": \"26\",\n",
    "            \"author\": \"Attwood\",\n",
    "            \"year\": \"2010\",\n",
    "            \"journal-title\": \"Bioinformatics\"\n",
    "          },\n",
    "          {\n",
    "            \"issue\": \"6\",\n",
    "            \"key\": \"10.3233/SW-150177_ref5\",\n",
    "            \"first-page\": \"515\",\n",
    "            \"article-title\": \"The collections ontology: creating and handling collections in OWL 2 DL frameworks\",\n",
    "            \"volume\": \"5\",\n",
    "            \"author\": \"Ciccarese\",\n",
    "            \"year\": \"2014\",\n",
    "            \"journal-title\": \"Semantic Web – Interoperability, Usability, Applicability\"\n",
    "          },\n",
    "        ]\n",
    "}\n",
    "first_ref = reference['reference'][1];\n",
    "process_ref_entry(first_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test a json file\n",
    "data = json.load(open('1000.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-25 11:41:11\n",
      "Processing:10.1002/ana.1266\n",
      "Processing:10.1002/ana.1269\n",
      "Processing:10.1002/app.2226\n",
      "Processing:10.1002/app.2235\n",
      "Processing:10.1002/app.10064\n",
      "Processing:10.1002/hyp.518\n",
      "Processing:10.1002/hyp.519\n",
      "Processing:10.1002/wcm.38\n",
      "Processing:10.1002/hyp.443\n",
      "Processing:10.1002/1097-0142(20010915)92:6<1531::aid-cncr1479>3.0.co;2-p\n",
      "Processing:10.1002/1521-3978(200112)49:12<1223::aid-prop1223>3.0.co;2-w\n",
      "Processing:10.1002/qua.1606\n",
      "Processing:10.1002/qua.1622\n",
      "Processing:10.1002/qua.1614\n",
      "Processing:10.1002/jclp.1109\n",
      "Processing:10.1002/(sici)1098-1101(1996)11:2<55::aid-jca1>3.0.co;2-9\n",
      "Processing:10.1002/dev.1003\n",
      "Processing:10.1002/1521-4141(200112)31:12<3484::aid-immu3484>3.0.co;2-5\n",
      "Processing:10.1002/(sici)1097-4547(19981015)54:2<254::aid-jnr13>3.0.co;2-4\n",
      "Processing:10.1002/(sici)1520-6823(1996)4:1<23::aid-roi4>3.0.co;2-o\n",
      "Processing:10.1002/(sici)1520-6823(1996)4:6<249::aid-roi1>3.0.co;2-y\n",
      "Processing:10.1002/(sici)1520-6823(1996)4:2<83::aid-roi6>3.0.co;2-h\n",
      "Processing:10.1002/(sici)1520-6823(1996)4:4<159::aid-roi2>3.0.co;2-x\n",
      "Processing:10.1002/(sici)1520-6823(1996)4:6<281::aid-roi6>3.0.co;2-u\n",
      "Processing:10.1002/(sici)1099-0518(19990301)37:5<615::aid-pola11>3.0.co;2-2\n",
      "Processing:10.1002/(sici)1099-0518(19990401)37:7<927::aid-pola9>3.0.co;2-9\n",
      "Processing:10.1002/(sici)1098-2280(1996)28:2<107::aid-em6>3.0.co;2-c\n",
      "Processing:10.1002/(sici)1098-2280(1997)29:3<296::aid-em10>3.0.co;2-9\n",
      "Processing:10.1002/(sici)1098-2280(1998)31:3<274::aid-em9>3.0.co;2-k\n",
      "Processing:10.1002/(sici)1098-2280(1998)32:4<377::aid-em12>3.0.co;2-1\n",
      "Processing:10.1002/(sici)1099-1654(199606)6:2<61::aid-rmv169>3.0.co;2-m\n",
      "Processing:10.1002/(sici)1099-0887(199601)12:1<13::aid-cnm944>3.0.co;2-r\n",
      "Processing:10.1002/(sici)1099-0887(199602)12:2<141::aid-cnm964>3.0.co;2-b\n",
      "Processing:10.1002/(sici)1099-0887(199608)12:8<497::aid-cnm997>3.0.co;2-h\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-77ed77cd7779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrosecond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocess_list_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrosecond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-23e5e7e13e56>\u001b[0m in \u001b[0;36mprocess_list_items\u001b[0;34m(obj, obj_file_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m##process the item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcsvdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#if this is the first time i am processing this element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-23e5e7e13e56>\u001b[0m in \u001b[0;36mprocess_item\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mref_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mref_entry_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_ref_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_entry_attr\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-23e5e7e13e56>\u001b[0m in \u001b[0;36mprocess_ref_entry\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"DOI\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mquery_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bibc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mnodoi_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-ae1650074fee>\u001b[0m in \u001b[0;36mfind_work\u001b[0;34m(query_txt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_work\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#call cross ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq_timeout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"errors\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-f4f74d78a259>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(query_text, is_json, query_type, num_iterations, sleep_time, req_timeout)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(api_call)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"useragent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mreq_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_cert_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcertfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     warnings.warn(\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    375\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                          _context=self)\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     def wrap_bio(self, incoming, outgoing, server_side=False,\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[1;32m    750\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(str(datetime.datetime.now().replace(microsecond=0)))\n",
    "process_list_items(data,1000)\n",
    "print(str(datetime.datetime.now().replace(microsecond=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to_iso8601(datetime.datetime.strptime('2015-02-01','%Y-%m-%d') - datetime.datetime.strptime('2016-02-01','%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 2, 1, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime('2015-02-01','%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P-365DT00H00M00S'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citing_dt = datetime.datetime.strptime('2015-02-01','%Y-%m-%d')\n",
    "cited_dt = datetime.datetime.strptime('2016-02-01','%Y-%m-%d')\n",
    "to_iso8601(citing_dt - cited_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1002/hyp.518\n",
      "10.1002/1097-0142(20010915)92:6<1531::aid-cncr1479>3.0.co;2-p\n"
     ]
    }
   ],
   "source": [
    "print(reverse_ci_to_doi(\"020010000023617342537050108\"))\n",
    "print(reverse_ci_to_doi(\"02001000002360100090763000104025802000001000901055909023806400105030138381018136312231227010407094203370037122439026325\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1002/(sici)1098-2280(1996)28:2<107::aid-em6>3.0.co;2-c\n"
     ]
    }
   ],
   "source": [
    "print(reverse_ci_to_doi(\"020010000023658281812185901000908630202080058010909065902083802400100073838101813631422064203370037122439026312\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterate all the input data and process the json files\n",
    "for subdir, dirs, files in os.walk(INPUT_DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.json'):\n",
    "            data = json.load(open(os.path.join(subdir, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
