{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import ReadTimeout, ConnectTimeout\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import urllib.parse\n",
    "import datetime\n",
    "import csv\n",
    "from time import sleep\n",
    "from duration import (\n",
    "    to_iso8601,\n",
    "    to_seconds,\n",
    "    to_timedelta,\n",
    "    to_tuple,\n",
    ")\n",
    "\n",
    "conf = {\n",
    "    \"email\": \"ivan.heibi2@unibo.it\",\n",
    "    \"key\": None,\n",
    "    \"useragent\": \"coci-process\",\n",
    "    \"postfix\": \"00000\"\n",
    "}\n",
    "\n",
    "\n",
    "CROSSREF_CODE = '020'\n",
    "LOOKUP_CSVPATH = 'lookup.csv'\n",
    "DATA_CSVPATH = \"data/d-%s.csv\"\n",
    "PROV_CSVPATH = 'prov/p-%s.csv'\n",
    "INDEX_PROCESSED_CSVPATH = 'index/processed.csv'\n",
    "INDEX_ERRORS_CSVPATH = 'index/error.csv'\n",
    "INDEX_DATE_CSVPATH = 'index/date.csv'\n",
    "INDEX_NODOI_CSVPATH = 'index/nodoi.csv'\n",
    "INDEX_FILE_CSVPATH = 'index/file.csv'\n",
    "\n",
    "INPUT_DATA_PATH = '.'\n",
    "\n",
    "MAX_DATA_ENTRIES = 5\n",
    "datacsv_counter = 0\n",
    "file_id = 0\n",
    "\n",
    "MIN_SCORE = 75\n",
    "crossref_api = {\n",
    "    'free_text' : 'https://api.crossref.org/works?rows=1&query=%s&mailto='+conf[\"email\"],\n",
    "    'doi' : 'https://api.crossref.org/works/&mailto='+conf[\"email\"]+'&query=%s'\n",
    "}\n",
    "\n",
    "lookup_code = 0\n",
    "\n",
    "#dictionaries \n",
    "lookup_dic = {}\n",
    "processed_dic = {}\n",
    "date_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### Methods to write on CSV files\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "#def write_row_on_csv(csv_path, new_row, csvid = None, quoting_val = csv.QUOTE_NONE):\n",
    "#    if csvid != None: \n",
    "#        csv_path = csv_path%(csvid)\n",
    "#    with open(csv_path, 'a', newline='') as csvfile:\n",
    "#        csvwriter = csv.writer(csvfile, quoting= quoting_val)\n",
    "#        csvwriter.writerow(new_row)\n",
    "\n",
    "#create new file with header\n",
    "def init_csv(csv_path,header):\n",
    "    with open(csv_path, 'w') as csvfile:\n",
    "        csvfile.write(header)\n",
    "\n",
    "#write on a csv_path file a given block_txt \n",
    "def write_txtblock_on_csv(csv_path, block_txt, csvid = None):\n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt)\n",
    "\n",
    "#write on a csv_path file a given rows (a list of values)\n",
    "def write_rows_on_csv(csv_path, row_lis, csvid = None, quoting_flag= True):\n",
    "    block_txt = \"\"\n",
    "    for row in row_lis:\n",
    "        row_txt = \"\"\n",
    "        separator = \",\"\n",
    "        for field_i in range(0,len(row)):\n",
    "            if (field_i == len(row) - 1):\n",
    "                separator = \"\"\n",
    "            field = row[field_i]\n",
    "            if quoting_flag:\n",
    "                field = '\"'+field+'\"'\n",
    "            row_txt = row_txt + field + separator\n",
    "        block_txt = block_txt + row_txt + \"\\n\"\n",
    "    \n",
    "    if csvid != None: \n",
    "        csv_path = csv_path%(csvid)\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        csvfile.write(block_txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#init the lookup_dic by the contents of its corresponding csv\n",
    "def init_lookup_dic():\n",
    "    with open(LOOKUP_CSVPATH,'r') as lookupcsv:\n",
    "        lookupcsv_reader = csv.DictReader(lookupcsv)\n",
    "        for row in lookupcsv_reader:\n",
    "            lookup_dic[row['c']] = row['code']\n",
    "        #last code used\n",
    "        global lookup_code\n",
    "        lookup_code = len(lookup_dic) - 1\n",
    "\n",
    "#update lookup dictionary and update its corresponding csv\n",
    "def update_lookup(c):\n",
    "    #define the code following the 9 rule ... \n",
    "    calc_next_lookup_code()\n",
    "    code = lookup_code  \n",
    "    global lookup_dic\n",
    "    lookup_dic[c] = code\n",
    "    #add it on the csv\n",
    "    write_txtblock_on_csv(LOOKUP_CSVPATH, '\\n\"%s\",\"%s\"'%(c,code))\n",
    "\n",
    "def update_date(dateObj, ci_key):\n",
    "    global date_dic\n",
    "    date_dic[ci_key] = dateObj\n",
    "    write_txtblock_on_csv(INDEX_DATE_CSVPATH, \"\\n\"+ci_key+\",\"+dateObj[\"str_val\"]+\",\"+str(dateObj[\"format\"]))\n",
    "    \n",
    "def init_date_dic():\n",
    "    with open(INDEX_DATE_CSVPATH,'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        global date_dic\n",
    "        for row in csv_reader:\n",
    "            date_dic[row['id']] = {\"str_val\": row['value'],\"format\": row['format']}\n",
    "            \n",
    "def update_processed(ci_key):\n",
    "    global processed_dic\n",
    "    processed_dic[ci_key] = 1\n",
    "    write_txtblock_on_csv(INDEX_PROCESSED_CSVPATH, \"\\n\"+ci_key)\n",
    "    \n",
    "def init_processed_dic():\n",
    "    with open(INDEX_PROCESSED_CSVPATH,'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        global processed_dic\n",
    "        for row in csv_reader:\n",
    "            processed_dic[row['id']] = 1\n",
    "            \n",
    "def update_nodoi(citing, cited, text):\n",
    "    write_txtblock_on_csv(INDEX_NODOI_CSVPATH, '\\n%s,%s,\"%s\"'%(citing,cited,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############  Convert CrossRef DOI to CI\n",
    "def calc_next_lookup_code():  \n",
    "    global lookup_code\n",
    "    rem = lookup_code % 100\n",
    "    newcode = lookup_code + 1\n",
    "    if (rem==89):\n",
    "        newcode = newcode * 10\n",
    "    lookup_code = newcode\n",
    "    \n",
    "#convert a crossref doi into a citation identifier     \n",
    "def convert_doi_to_ci(doi_str):\n",
    "    return CROSSREF_CODE + match_str_to_lookup(doi_str)\n",
    "   \n",
    "#convert a giving string in its corresponding ci format\n",
    "#using the lookup file\n",
    "def match_str_to_lookup(str_val):\n",
    "    ci_str = \"\"\n",
    "    str_noprefix = str_val[3:]\n",
    "    for c in str_noprefix:\n",
    "        if c not in lookup_dic:\n",
    "            update_lookup(c)\n",
    "        ci_str = ci_str + str(lookup_dic[c])\n",
    "    return ci_str    \n",
    "\n",
    "def reverse_ci_to_doi(str_val):\n",
    "    str_val = str_val[3:]\n",
    "    str_doi=\"\"\n",
    "    i=0\n",
    "    while i < len(str_val):\n",
    "        code = str_val[i:i+2]\n",
    "        \n",
    "        for key in lookup_dic:\n",
    "            if lookup_dic[key] == code:\n",
    "                    str_doi = str_doi + key\n",
    "        i += 2\n",
    "    return \"10.\"+str_doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build a bib citation with all the available info inside the reference object \n",
    "def build_bibc(obj):\n",
    "    \n",
    "    if 'unstructured' in obj:\n",
    "        return obj['unstructured']\n",
    "    else:\n",
    "        #all att values are already in string format\n",
    "        bibc = \"\"\n",
    "        strspan= \" \"\n",
    "        if 'author' in obj:\n",
    "            bibc = bibc + obj['author'] + strspan          \n",
    "        if 'year' in obj:\n",
    "            bibc = bibc + obj['year'] + strspan\n",
    "        if 'article-title' in obj:\n",
    "            bibc = bibc + obj['article-title'] + strspan\n",
    "        if 'volume-title' in obj:\n",
    "            bibc = bibc + obj['volume-title'] + strspan\n",
    "        if 'journal-title' in obj:\n",
    "            bibc = bibc + obj['journal-title'] + strspan\n",
    "        if 'volume' in obj:\n",
    "            bibc = bibc + obj['volume'] + strspan\n",
    "        if 'first-page' in obj:\n",
    "            bibc = bibc + obj['first-page'] + strspan\n",
    "        if 'last-page' in obj:\n",
    "            bibc = bibc + obj['last-page'] + strspan\n",
    "        return bibc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call crossref with the corresponding crossref_api[query_type] and the query_text \n",
    "def get_data(query_text, is_json = True, query_type = \"free_text\", num_iterations= 1, sleep_time= 60,req_timeout= None):\n",
    "    api_url = crossref_api[query_type]\n",
    "    errors = \"\"\n",
    "    for i in range(0,num_iterations):\n",
    "        api_call = api_url % (urllib.parse.quote_plus(query_text))\n",
    "        #print(api_call)\n",
    "        try:\n",
    "            response = requests.get(api_call, headers={\"User-Agent\": conf[\"useragent\"]}, timeout= req_timeout)\n",
    "            if (response.status_code == 200):\n",
    "                if is_json:\n",
    "                    return json.loads(response.text)\n",
    "                else:\n",
    "                    return response.text\n",
    "            else:\n",
    "                errors = errors + \"HTTP error on data retrieving (HTTP status code: %s). \" % str(response.status_code)\n",
    "        except Exception as e:\n",
    "            errors = errors + \"Exception: %s \" % e\n",
    "        \n",
    "        #try again after a sleep_time period\n",
    "        sleep(sleep_time)\n",
    "    \n",
    "    #if the method arrives here, we got some errors\n",
    "    return {\"errors\": errors} \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the publication-date of a given crossref work object\n",
    "def build_pubdate(obj, ci):\n",
    "    \n",
    "    if ci in date_dic:\n",
    "        return date_dic[ci]\n",
    "    \n",
    "    if 'issued' in obj:\n",
    "        if 'date-parts' in obj['issued']:\n",
    "            #is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj['issued']['date-parts'][0]\n",
    "                \n",
    "                #lisdate[year,month,day]\n",
    "                listdate = [1,1,1]\n",
    "                for i in range(0,len(obj_date)):\n",
    "                    try:\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                #I have a date , so generate it\n",
    "                if (listdate[0] != 1):\n",
    "                    date_val = datetime.date(listdate[0], listdate[1], listdate[2])\n",
    "                    \n",
    "                    dformat = '%Y-%m-%d'\n",
    "                    #e.g: 2016/1/1\n",
    "                    if ((listdate[1] == 1) and (listdate[2] == 1)):\n",
    "                        dformat = '%Y'\n",
    "\n",
    "                    #e.g: 2016/3/1\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    \n",
    "                    dateobj = {\"str_val\": date_in_str, \"format\":  dformat}\n",
    "                    #date_dic[ci] = dateobj\n",
    "                    return dateobj\n",
    "                \n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "    #date_dic[ci] = {\"str_val\":\"\",\"format\":-1}\n",
    "    return {\"str_val\":\"\",\"format\":-1}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given a textual input (query_txt), call crossref and retrieves the work object of \n",
    "# the best scoring result in case the score is higher than MIN_SCORE\n",
    "def find_work(query_txt):\n",
    "    #call cross ref \n",
    "    res = get_data(query_txt, num_iterations=2, req_timeout= 60)\n",
    "    \n",
    "    if \"errors\" not in res:\n",
    "        try:\n",
    "            #crossref first and only result with higher score\n",
    "            work_item = res['message']['items'][0]\n",
    "\n",
    "            if \"score\" in work_item:\n",
    "                if work_item[\"score\"] > MIN_SCORE:\n",
    "                    #check if the work has a DOI\n",
    "                    if \"DOI\" in work_item:\n",
    "                        return work_item\n",
    "                    else:\n",
    "                        return -1\n",
    "                #low score\n",
    "                return -1\n",
    "        except IndexError:\n",
    "                return -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_list_items(obj, obj_file_id):\n",
    "    list_of_items = obj['message']['items']\n",
    "    for item in list_of_items:\n",
    "        ##process the item \n",
    "        csvdata = process_item(item)\n",
    "        \n",
    "        #if this is the first time i am processing this element\n",
    "        if csvdata != -1:\n",
    "            if \"errors\" in csvdata:\n",
    "                #write the errors\n",
    "                write_txtblock_on_csv(INDEX_ERRORS_CSVPATH, '\\n%s,\"%s\"'%(csvdata[\"citing_ci\"],csvdata['errors']))\n",
    "\n",
    "            else:    \n",
    "                global datacsv_counter\n",
    "                global file_id\n",
    "                \n",
    "                #update files identifiers\n",
    "                datacsv_counter += 1\n",
    "                if (datacsv_counter // MAX_DATA_ENTRIES == 1):\n",
    "                    datacsv_counter = 0\n",
    "                    file_id += 1 \n",
    "                    init_csv(DATA_CSVPATH%str(file_id),'oci,citing,cited,creation,timestamp')\n",
    "                    init_csv(PROV_CSVPATH%str(file_id),'oci,agent,source,datetime')\n",
    "                \n",
    "                if csvdata[\"data\"] != \"\":\n",
    "                    write_txtblock_on_csv(DATA_CSVPATH, csvdata[\"data\"], csvid = str(file_id))\n",
    "                if csvdata[\"prov\"] != \"\":\n",
    "                    write_txtblock_on_csv(PROV_CSVPATH, csvdata[\"prov\"], csvid = str(file_id))\n",
    "\n",
    "            #add item to processed \n",
    "            write_txtblock_on_csv(INDEX_PROCESSED_CSVPATH, \"\\n%s\"%(csvdata[\"citing_ci\"]))\n",
    "            \n",
    "    write_txtblock_on_csv(INDEX_FILE_CSVPATH, \"\\n%s\"%(str(obj_file_id)))\n",
    "        \n",
    "#given a crossref object get all the COCI data needed, returns an object with errors in case something wrong happend \n",
    "#returns -1 in case the object has already been processed\n",
    "def process_item(obj):\n",
    "    data_lis = []\n",
    "    prov_lis = []\n",
    "    \n",
    "    if ((\"DOI\" in obj) and (\"reference\" in obj)):\n",
    "        print(\"Processing:\"+obj[\"DOI\"])\n",
    "        citing_doi = obj[\"DOI\"].lower()\n",
    "        citing_ci = convert_doi_to_ci(citing_doi)\n",
    "        citing_date = build_pubdate(obj,citing_ci)\n",
    "        \n",
    "        #update dates\n",
    "        update_date(citing_date, citing_ci)\n",
    "        \n",
    "        #in case this is the first time i am elaborating this item\n",
    "        if citing_ci not in processed_dic:\n",
    "            update_processed(citing_ci)\n",
    "                \n",
    "            data_txtblock = \"\"\n",
    "            prov_txtblock = \"\"\n",
    "            \n",
    "            #iterate through all references\n",
    "            for ref_item in obj['reference']:\n",
    "                \n",
    "                ref_entry_attr = process_ref_entry(ref_item)\n",
    "                \n",
    "                if(ref_entry_attr != -1):\n",
    "                    if(\"errors\" not in ref_entry_attr): \n",
    "                        \n",
    "                        #in case It was a No-DOI \n",
    "                        if (ref_entry_attr[\"nodoi_text\"] != -1):\n",
    "                            update_nodoi(citing_ci, ref_entry_attr['cited_ci'], ref_entry_attr[\"nodoi_text\"])\n",
    "                        \n",
    "                        #create all other data needed\n",
    "                        oci = citing_ci+\"-\"+ref_entry_attr['cited_ci']\n",
    "                        \n",
    "                        timestamp = \"\"\n",
    "                        if ((citing_date[\"format\"] != -1) and (ref_entry_attr['cited_date'][\"format\"] != -1)):\n",
    "                            \n",
    "                            citing_dt = datetime.datetime.strptime(citing_date[\"str_val\"], citing_date[\"format\"])\n",
    "                            cited_dt = datetime.datetime.strptime(ref_entry_attr['cited_date'][\"str_val\"], ref_entry_attr['cited_date'][\"format\"])\n",
    "                            timestamp = to_iso8601(citing_dt - cited_dt)\n",
    "                        \n",
    "                        data_txtblock = data_txtblock +\"\\n\"+ oci+\",\"+citing_doi+\",\"+ref_entry_attr['cited_doi']+\",\"+citing_date[\"str_val\"]+\",\"+timestamp\n",
    "                        \n",
    "                        timenow = str(datetime.datetime.now().replace(microsecond=0))\n",
    "                        prov_txtblock = prov_txtblock +\"\\n\"+ oci+\",\"+conf[\"useragent\"]+\",\"+crossref_api['doi']+citing_doi+\",\"+timenow\n",
    "                    #we have errors\n",
    "                    else:\n",
    "                        #break all and return the errors\n",
    "                        return {\"errors\": ref_entry_attr[\"errors\"], \"citing_ci\": citing_ci}\n",
    "                        break;\n",
    "                \n",
    "            return {\n",
    "                \"citing_ci\": citing_ci,\n",
    "                \"data\": data_txtblock,\n",
    "                \"prov\": prov_txtblock\n",
    "            }\n",
    "        return - 1\n",
    "    return {\"errors\": \"entry without a DOI or Ref-List\"}\n",
    "            \n",
    "#given a reference entry returns it's DOI, CI, and Publication-Date    \n",
    "#in case one of these attributes is not present: the methods returns -1\n",
    "def process_ref_entry(obj):\n",
    "    \n",
    "    nodoi_text = -1\n",
    "    \n",
    "    #check if obj have a DOI if not call crossref\n",
    "    if \"DOI\" not in obj :\n",
    "        query_text = build_bibc(obj)\n",
    "        obj = find_work(query_text)\n",
    "        if (obj != -1):\n",
    "            nodoi_text = query_text\n",
    "    \n",
    "    if (obj != -1):\n",
    "        if \"errors\" in obj:\n",
    "            return obj\n",
    "        else:\n",
    "            #if my new object have a doi now\n",
    "            if \"DOI\" in obj:\n",
    "                cited_doi = obj[\"DOI\"]\n",
    "                cited_ci = convert_doi_to_ci(cited_doi)\n",
    "\n",
    "                #check if obj have a publcation date, \n",
    "                #first case is true only if find_work has been called before\n",
    "                cited_date = build_pubdate(obj,cited_ci)\n",
    "                \n",
    "                #in case i don't have a date, try look at it again\n",
    "                if cited_date[\"format\"] == -1 :\n",
    "                    obj = get_data(cited_doi, query_type = \"doi\", num_iterations=3, req_timeout=60)\n",
    "                    if \"errors\" not in obj:\n",
    "                        cited_date = build_pubdate(obj['message'],cited_ci)\n",
    "                \n",
    "                #update dates\n",
    "                update_date(cited_date, cited_ci)\n",
    "                \n",
    "                return {'cited_doi': cited_doi, 'cited_ci': cited_ci, 'cited_date':cited_date, 'nodoi_text':nodoi_text }\n",
    "    else:\n",
    "        return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterate all the input data and process the json files\n",
    "for subdir, dirs, files in os.walk(INPUT_DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.json'):\n",
    "            data = json.load(open(os.path.join(subdir, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
